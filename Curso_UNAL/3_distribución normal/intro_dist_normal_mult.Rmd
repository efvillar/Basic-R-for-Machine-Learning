---
title: "Introducción a la normal multivariada"
author: "Juan David Ospina Arango <br/> Universidad Nacional de Colombia - Sede Medellín <br/> Departamento de Ciencias de la Computación y de la Decisión <br/> Analítica Predictiva"
date: "29 de junio de 2019"
output:
  html_document: default
  html_notebook: default
---


# Introducción
A continuación se presentan algunos aspectos de la distribución normal multivariada a través de gráficos y simulaciones en R. Se utilizará la librería *mvtnorm*:

```{r}
library(mvtnorm)
```

Para esta ilustración se utilizará una distribución normal de tres dimensiones. 

## Paso 1: definir la matriz de correlaciones
El pensar en correlaciones en lugar de covarianzas puede evitar los problemas que conlleva los cambios de escala de las diferentes variables. Como se trata de una distribución de 3 variables la matriz de covarianzas tendrá 9 componentes y $3\times\left(3+1 \right)/2$ elementos distintos.

```{r}
M_cor<-matrix(c(1,0.8,0.8,0.8,1,0.8,0.8,0.8,1),ncol=3)
print(M_cor)
```

## Paso 2: obtener una matriz de covarianzas propia
Ahora, utilizando la función *cor2cov()* de la librería *MBESS* se convierte la matriz de correlación en una matriz de covarianza. En este paso debemos definir las escalas (desviaciones estándar) de cada una de las variables.

```{r message=FALSE, warning=FALSE}
library(MBESS)
M_cov<-cor2cov(M_cor,sd=c(1.2,1.3,2))
print(M_cov)
```

Ahora debemos asegurarnos de tener una matriz de covarianzas [definida positiva](https://en.wikipedia.org/wiki/Positive-definite_matrix). Para ello utilizamos la función *nearPD* de la librería *Matrix*:

```{r message=FALSE, warning=FALSE}
library(Matrix)
M_cov_pd<-as.matrix(nearPD(M_cov)$mat)
print(M_cov_pd)
```

## Paso 3: simulamos dos muestras con la misma dispersión y diferentes vectores de medias
A continuación se definen los tamaños muestrales y vectores de medias de dos muestras que se generarán de dos distribuciones normales trivariadas:

```{r}
n1<-50 # Tamaño de la muestra 1
n2<-80 # Tamaño de la muestra 2
mu1<-c(1,1.5,1) # Vector de medias de la muestra 1
mu2<-c(-1,1.5,1) # Vector de medias de la muestra 2
```

Ahora se simulan las dos muestras y se concatenan en una matriz. Para obtener resultados reproducibles se fija la semilla del generador de números aleatorios con la función *set.seed()*:

```{r}
set.seed(1)
muestra1<-rmvnorm(n=n1,mean=mu1,sigma=M_cov_pd,method="eigen")
muestra2<-rmvnorm(n=n2,mean=mu2,sigma=M_cov_pd,method="eigen")
muestra<-rbind(muestra1,muestra2)
```

El siguiente código crea la columna de clase ("1" ó "2") y concatena la matrix con las muestras y la columna de clase en un dataframe:
```{r}
clase<-c(rep("1",n1),rep("2",n2))
muestra_df<-data.frame(muestra,clase)
```

## Gráfica de dispersión por pares:
Con el comando *pairs()* hacemos el gráfico de dispersión por pares:

```{r}
pairs(muestra_df[,1:3],col=muestra_df$clase)
```

¿Qué conclusiones podemos sacar de este gráfico?


## Curvas de nivel muestrales
Utilizando la función *kde()* de la librería *ks* podemos obtener las curvas de nivel muestrales (por pares de variables).

El siguiente código muestra cómo hacerlo para las variables $X_1$ y $X_2$ de la muestra 1:

```{r message=FALSE, warning=FALSE}
library(ks)
fhat.muestra1 <- kde(x=muestra1[,c(1,2)], binned=TRUE)
plot(fhat.muestra1, display="filled.contour2", cont=seq(10,90,by=10))
grid()
```

¿Qué pasa con la forma de esta gráfica a medida que $n_1$ crece?



El siguietne código extrae la magnitud de la densidad correspondiente que crea el conjunto de nivel que encierra una region de probabilidad $1-cont$. Esto es el numero $d$ tal que $P\left( x \in R\left(d\right) \right)=1-cont$, con $R(d)=\{x|f(x)>d\}$:

```{r}
contourLevels(fhat.muestra1, cont=c(75, 50, 25))
```


# Predicción de $X_1$ dados $X_2$ y $X_3$:
Ahora calculamos, para la muestra 1, la mejor predicción de $X_1$ dados $X_2$ y $X_3$ con la siguiente fórmula:

$\hat{X}_1=\mu_1+\Sigma^{T}_{1,23}\Sigma^{-1}_{23}\left(\left(X_2,X_3 \right)^{T}-\mu_{23}\right)$:

```{r}
X1_hat<-mu1[1]+M_cov_pd[1,2:3]%*%solve(M_cov_pd[2:3,2:3])%*%(t(muestra1[,2:3])-mu1[2:3])
plot(muestra1[,1],X1_hat,ylab="X1 estimado",xlab="X1 real")
abline(a=0,b=1)
grid()
```

1. ¿Qué pasa a medida que el tamaño de la muestra crece? 
2. ¿Qué pasa cuando la correlación entre las variables se debilita? 
3. ¿Qué pasa cuando $X_2$ y $X_3$ son poco correlacionadas entre sí pero correlacionadas con $X_1$?


## FIN







